{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import zeros, transpose, asarray, sum,  diag, dot, arccos\n",
    "from numpy.linalg import norm\n",
    "import numpy\n",
    "from scipy.linalg import svd, inv\n",
    "import matplotlib.pyplot as plt\n",
    "import re, random, pylab\n",
    "from math import * \n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stopwords, retreived from http://www.lextek.com/manuals/onix/stopwords1.html\n",
    "\n",
    "stopwords = ['a', 'about', 'above', 'across', 'after', 'again', 'against', \n",
    "'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', \n",
    "'among', 'an', 'and', 'another', 'any', 'anybody', 'anyone', 'anything', \n",
    "'anywhere', 'are', 'area', 'areas', 'around', 'as', 'ask', 'asked', \n",
    "'asking', 'asks', 'at', 'away', 'b', 'back', 'backed', 'backing', 'backs', 'be', \n",
    "'became', 'because', 'become', 'becomes', 'been', 'before', 'began', 'behind', \n",
    "'being', 'beings', 'best', 'better', 'between', 'big', 'both', 'but', 'by', 'c', \n",
    "'came', 'can', 'cannot', 'case', 'cases', 'certain', 'certainly', 'clear', 'clearly', \n",
    "'come', 'could', 'd', 'did', 'differ', 'different', 'differently', 'do', 'does', 'done', \n",
    "'down', 'down', 'downed', 'downing', 'downs', 'during', 'e', 'each', 'early', 'either', \n",
    "'end', 'ended', 'ending', 'ends', 'enough', 'even', 'evenly', 'ever', 'every', 'everybody', \n",
    "'everyone', 'everything', 'everywhere', 'f', 'face', 'faces', 'fact', 'facts', 'far', \n",
    "'felt', 'few', 'find', 'finds', 'first', 'for', 'four', 'from', 'full', 'fully', \n",
    "'further', 'furthered', 'furthering', 'furthers', 'g', 'gave', 'general', 'generally', \n",
    "'get', 'gets', 'give', 'given', 'gives', 'go', 'going', 'good', 'goods', 'got', 'great', \n",
    "'greater', 'greatest', 'group', 'grouped', 'grouping', 'groups', 'h', 'had', 'has', 'have', \n",
    "'having', 'he', 'her', 'here', 'herself', 'high', 'high', 'high', 'higher', 'highest', \n",
    "'him', 'himself', 'his', 'how', 'however', 'i', 'if', 'important', 'in', 'interest', \n",
    "'interested', 'interesting', 'interests', 'into', 'is', 'it', 'its', 'itself', 'j', \n",
    "'just', 'k', 'keep', 'keeps', 'kind', 'knew', 'know', 'known', 'knows', 'l', 'large', 'largely', \n",
    "'last', 'later', 'latest', 'least', 'less', 'let', 'lets', 'like', 'likely', 'long', 'longer',\n",
    "'longest', 'm', 'made', 'make', 'making', 'man', 'many', 'may', 'me', 'member', 'members', \n",
    "'men', 'might', 'more', 'most', 'mostly', 'mr', 'mrs', 'much', 'must', 'my', 'myself', \n",
    "'n', 'necessary', 'need', 'needed', 'needing', 'needs', 'never', 'new', 'new', 'newer',\n",
    "'newest', 'next', 'no', 'nobody', 'non', 'noone', 'not', 'nothing', 'now', 'nowhere', \n",
    "'number', 'numbers', 'o', 'of', 'off', 'often', 'old', 'older', 'oldest', 'on',\n",
    "'once', 'one', 'only', 'open', 'opened', 'opening', 'opens', 'or', 'order', \n",
    "'ordered', 'ordering', 'orders', 'other', 'others', 'our', 'out', 'over', 'p', \n",
    "'part', 'parted', 'parting', 'parts', 'per', 'perhaps', 'place', 'places', 'point',\n",
    "'pointed', 'pointing', 'points', 'possible', 'present', 'presented', 'presenting', \n",
    "'presents', 'problem', 'problems', 'put', 'puts', 'q', 'quite', 'r', 'rather', \n",
    "'really', 'right', 'right', 'room', 'rooms', 's', 'said', 'same', 'saw', 'say', \n",
    "'says', 'second', 'seconds', 'see', 'seem', 'seemed', 'seeming', 'seems', \n",
    "'sees', 'several', 'shall', 'she', 'should', 'show', 'showed', 'showing', \n",
    "'shows', 'side', 'sides', 'since', 'small', 'smaller', 'smallest', 'so', \n",
    "'some', 'somebody', 'someone', 'something', 'somewhere', 'state', 'states', \n",
    "'still', 'still', 'such', 'sure', 't', 'take', 'taken', 'than', 'that', 'the', \n",
    "'their', 'them', 'then', 'there', 'therefore', 'these', 'they', 'thing', 'things', \n",
    "'think', 'thinks', 'this', 'those', 'though', 'thought', 'thoughts', 'three', \n",
    "'through', 'thus', 'to', 'today', 'together', 'too', 'took', 'toward', 'turn', \n",
    "'turned', 'turning', 'turns', 'two', 'u', 'under', 'until', 'up', 'upon', \n",
    "'us', 'use', 'used', 'uses', 'v', 'very', 'w', 'want', 'wanted', 'wanting', \n",
    "'wants', 'was', 'way', 'ways', 'we', 'well', 'wells', 'went', 'were', \n",
    "'what', 'when', 'where', 'whether', 'which', 'while', 'who', 'whole', 'whose', \n",
    "'why', 'will', 'with', 'within', 'without', 'work', 'worked', 'working', 'works', \n",
    "'would', 'x', 'y', 'year', 'years', 'yet', 'you', 'young', 'younger', 'youngest', 'your', \n",
    "'yours', 'z']\n",
    "ignore_characters = ''',:'!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare(query1, query2): # core comparison function.\n",
    "    query1=query1 + \" Dummy\"\n",
    "    query2=query2 + \" Dummy\"\n",
    "    lsa = LSA(stopwords, ignore_characters)\n",
    "    queries = [query1,query2]\n",
    "    for q in queries:\n",
    "        lsa.parse(q)\n",
    "    lsa.build()\n",
    "    lsa.calc()\n",
    "    Vt = lsa.Vt\n",
    "    S = diag(lsa.S)\n",
    "    #print(Vt.shape)\n",
    "    #print(S.shape)\n",
    "    vectors =[(dot(S,Vt[:,0]),dot(S,Vt[:,i])) for i in range(len(Vt))]\n",
    "    angles = [arccos(dot(a,b)/(norm(a,2)*norm(b,2))) for a,b in vectors[1:]]\n",
    "    #print(len(vectors))\n",
    "    #print(len(angles))\n",
    "    if len(angles) == 0:\n",
    "        return 0\n",
    "    else :\n",
    "        return str(abs(1 - float(angles[0])/float(pi/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSA(object):\n",
    "    def __init__(self, stopwords, ignore_characters):\n",
    "        self.stopwords = stopwords\n",
    "        self.ignore_characters = ignore_characters\n",
    "        self.wdict = {}\n",
    "        self.dcount = 0        \n",
    "    def parse(self, doc):\n",
    "        words = doc.split();\n",
    "        for w in words:\n",
    "            w = w.lower()\n",
    "            #.translate(None, self.ignore_characters)\n",
    "            if w in self.stopwords:\n",
    "                continue\n",
    "            elif w in self.wdict:\n",
    "                self.wdict[w].append(self.dcount)\n",
    "            else:\n",
    "                self.wdict[w] = [self.dcount]\n",
    "        self.dcount += 1      \n",
    "    def build(self): # Create count matrix\n",
    "        self.keys = [k for k in self.wdict.keys() if len(self.wdict[k]) > 1]\n",
    "        #if len(self.keys)==0:\n",
    "         #   self.wdict[\"Dummy\"] = [0]\n",
    "          #  self.keys.append(\"Dummy\")\n",
    "        self.keys.sort()\n",
    "        self.A = zeros([len(self.keys), self.dcount])\n",
    "        for i, k in enumerate(self.keys):\n",
    "            for d in self.wdict[k]:\n",
    "                self.A[i,d] += 1\n",
    "    def calc(self): # execute SVD\n",
    "        #print(self.A.shape)\n",
    "        self.U, self.S, self.Vt = svd(self.A, full_matrices =False)\n",
    "    def TFIDF(self): # calculate tfidf score\n",
    "        WordsPerDoc = sum(self.A, axis=0)        \n",
    "        DocsPerWord = sum(asarray(self.A > 0, 'i'), axis=1)\n",
    "        rows, cols = self.A.shape\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                self.A[i,j] = (self.A[i,j] / WordsPerDoc[j]) * log(float(cols) / DocsPerWord[i])\n",
    "    def S(self):\n",
    "        return self.S\n",
    "    def U(self):\n",
    "        return -1 * self.U\n",
    "    def Vt(self):\n",
    "        return -1 * self.Vt\n",
    "    #def printSVD(self):\n",
    "        #print('Singular values: ')\n",
    "        #print(self.S)\n",
    "        #print('U matrix: ')\n",
    "        #print(-1*self.U[:, 0:3])\n",
    "        #print('Vt matrix:) '\n",
    "        #print(-1*self.Vt[0:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare('30-year-old Moscow resident was hospitalized with wounds very intimate nature. As it became known LifeNews, in the hands of doctors, the man complained that his casual acquaintance opoila in the sauna, and then gently held his castration operation. And actions criminals were executed with surgical precision - woman sewed all the smallest blood vessels.', 'Mark Zuckerberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare('Hundreds of Palestinians were evacuated from their homes Sunday morning after Israeli authorities opened a number of dams near the border, flooding the Gaza Valley in the wake of a recent severe winter storm.','Hundreds of Palestinians flee floods in Gaza as Israel opens dams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.07627295930784783'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare('Many are expecting Apple talk more about the Apple Watch. However, sources familiar with the matter within Apple have exclusively told The Michael Report that Apple plans to unveil the long-awaited Retina MacBook Air at the same event. The Michael Report has independently verified this information to be highly credible. We should note that this information falls in line with what Apple analysts such as KGI Securities’ Ming-Chi Kuo and Oppenheimer’s Andrew Uerkwitz have been predicting for months. Supply chain sources who spoke to the press have also said that Apple ramped up their production in late 2014 and entered the mass production stage in December, with the goal of producing enough units for an early-2015 debut. Last week, Apple sent out the invites for its “Spring Forward” event, slated to be held at the Yerba Buena Center for the Arts in San Francisco on March 9th.','Woman has surgery to get third breast: The three most statistically unlikely pairs of boobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(compare('Many are expecting Apple talk more about the Apple Watch. However, sources familiar with the matter within Apple have exclusively told The Michael Report that Apple plans to unveil the long-awaited Retina MacBook Air at the same event. The Michael Report has independently verified this information to be highly credible. We should note that this information falls in line with what Apple analysts such as KGI Securities’ Ming-Chi Kuo and Oppenheimer’s Andrew Uerkwitz have been predicting for months. Supply chain sources who spoke to the press have also said that Apple ramped up their production in late 2014 and entered the mass production stage in December, with the goal of producing enough units for an early-2015 debut. Last week, Apple sent out the invites for its “Spring Forward” event, slated to be held at the Yerba Buena Center for the Arts in San Francisco on March 9th.','Woman has surgery to get third breast: The three most statistically unlikely pairs of boobs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "\n",
    "class DataSet():\n",
    "    def __init__(self, name=\"train\", path=\"fnc-1\"):\n",
    "        self.path = path\n",
    "\n",
    "        print(\"Reading dataset\")\n",
    "        bodies = name+\"_bodies.csv\"\n",
    "        stances = name+\"_stances.csv\"\n",
    "\n",
    "        self.stances = self.read(stances)\n",
    "        articles = self.read(bodies)\n",
    "        self.articles = dict()\n",
    "\n",
    "        #make the body ID an integer value\n",
    "        for s in self.stances:\n",
    "            s['Body ID'] = int(s['Body ID'])\n",
    "\n",
    "        #copy all bodies into a dictionary\n",
    "        for article in articles:\n",
    "            self.articles[int(article['Body ID'])] = article['articleBody']\n",
    "\n",
    "        print(\"Total stances: \" + str(len(self.stances)))\n",
    "        print(\"Total bodies: \" + str(len(self.articles)))\n",
    "\n",
    "\n",
    "\n",
    "    def read(self,filename):\n",
    "        rows = []\n",
    "        with open(self.path + \"/\" + filename, \"r\", encoding='utf-8') as table:\n",
    "            r = DictReader(table)\n",
    "\n",
    "            for line in r:\n",
    "                rows.append(line)\n",
    "        return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n"
     ]
    }
   ],
   "source": [
    "trainD = DataSet(name=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Headline',\n",
       "              \"Police find mass graves with at least '15 bodies' near Mexico town where 43 students disappeared after police clash\"),\n",
       "             ('Body ID', 712),\n",
       "             ('Stance', 'unrelated')])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainD.stances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainD.stances[0]\n",
    "for stance in trainD.stances:\n",
    "    tempStance = stance['Stance']\n",
    "    if tempStance == 'disagree':\n",
    "        stance['Stance'] = 'unrelated'\n",
    "    elif tempStance != 'unrelated':\n",
    "        stance['Stance'] = 'related'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902705515088\n",
      "done\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "#Threshold manually varied and re-run several times to find the optimal threshold of 0.18\n",
    "%%time\n",
    "threshold=0.18\n",
    "headlines_train = []\n",
    "bodies_train = []\n",
    "y_out_train = []\n",
    "train_pred = []\n",
    "Train_feature_list = []\n",
    "TP=0\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "for stance in trainD.stances:\n",
    "    bid = stance['Body ID']\n",
    "    bodies_train.append(trainD.articles[bid])\n",
    "    headlines_train.append(stance['Headline'])\n",
    "    y_out_train.append(stance['Stance']=='related')\n",
    "    comparison=compare(stance['Headline'],trainD.articles[bid])\n",
    "    Train_feature_list.append(comparison)\n",
    "    if float(comparison)>threshold:\n",
    "        train_pred.append(1)\n",
    "        #print(\"Threshold = \",threshold,' Iteration = ',i)\n",
    "        i+=1\n",
    "    else:\n",
    "        train_pred.append(0)\n",
    "        #print('Iteration = ',i)\n",
    "        i+=1\n",
    "correct = [ i==j for i,j in zip(train_pred,y_out_train)]\n",
    "for i,j in zip(train_pred,y_out_train):\n",
    "    if (i==1) & (j==1):\n",
    "        TP+=1\n",
    "    elif (i==0) & (j==0):\n",
    "        TN+=1\n",
    "    elif (i==1) & (j==1):\n",
    "        FP+=1\n",
    "    else:\n",
    "        FN+=1\n",
    "    \n",
    "#TP += [(i==1)&(j==1) for i,j in zip(test_pred,y_out_test)] \n",
    "#TN += [i==0&j==0 for i,j in zip(test_pred,y_out_test)]\n",
    "#FP += [i==1&j==0 for i,j in zip(test_pred,y_out_test)]\n",
    "#FN += [i==0&j==1 for i,j in zip(test_pred,y_out_test)]\n",
    "\n",
    "\n",
    "print(sum(correct)*1.0/len(correct))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|TP  9957 \n",
      "|TN  35153 \n",
      "|FP  0 \n",
      "|FN  4862\n"
     ]
    }
   ],
   "source": [
    "print(\"|TP \",TP,\"\\n|TN \",TN,\"\\n|FP \",FP,\"\\n|FN \",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BER is  0.1640461569606586\n"
     ]
    }
   ],
   "source": [
    "BER = 1-(0.5*((TP/(TP+FN))+(TN/(TN+FP))))\n",
    "print(\"The BER is \", BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49972"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling body vectors\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Pickling body vectors\")\n",
    "import pickle\n",
    "with open('LSA_Compare_Features_Train.pkl','wb') as f:\n",
    "    pickle.dump(Train_feature_list,f)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "testD = DataSet(name=\"competition_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Headline',\n",
       "              'Ferguson riots: Pregnant woman loses eye after cops fire BEAN BAG round through car window'),\n",
       "             ('Body ID', 2008),\n",
       "             ('Stance', 'unrelated')])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testD.stances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testD.stances[0]\n",
    "for stance in testD.stances:\n",
    "    tempStance = stance['Stance']\n",
    "    if tempStance == 'disagree':\n",
    "        stance['Stance'] = 'unrelated'\n",
    "    elif tempStance != 'unrelated':\n",
    "        stance['Stance'] = 'related'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "threshold=0.18\n",
    "headlines_test = []\n",
    "bodies_test = []\n",
    "y_out_test = []\n",
    "test_pred = []\n",
    "feature_list = []\n",
    "TP=0\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "for stance in testD.stances:\n",
    "    bid = stance['Body ID']\n",
    "    bodies_test.append(testD.articles[bid])\n",
    "    headlines_test.append(stance['Headline'])\n",
    "    y_out_test.append(stance['Stance']=='related')\n",
    "    comparison=compare(stance['Headline'],testD.articles[bid])\n",
    "    feature_list.append(comparison)\n",
    "    if float(comparison)>threshold:\n",
    "        test_pred.append(1)\n",
    "        #print(\"Threshold = \",threshold,' Iteration = ',i)\n",
    "        i+=1\n",
    "    else:\n",
    "        test_pred.append(0)\n",
    "        #print('Iteration = ',i)\n",
    "        i+=1\n",
    "correct = [ i==j for i,j in zip(test_pred,y_out_test)]\n",
    "for i,j in zip(test_pred,y_out_test):\n",
    "    if (i==1) & (j==1):\n",
    "        TP+=1\n",
    "    elif (i==0) & (j==0):\n",
    "        TN+=1\n",
    "    elif (i==1) & (j==1):\n",
    "        FP+=1\n",
    "    else:\n",
    "        FN+=1\n",
    "    \n",
    "#TP += [(i==1)&(j==1) for i,j in zip(test_pred,y_out_test)] \n",
    "#TN += [i==0&j==0 for i,j in zip(test_pred,y_out_test)]\n",
    "#FP += [i==1&j==0 for i,j in zip(test_pred,y_out_test)]\n",
    "#FN += [i==0&j==1 for i,j in zip(test_pred,y_out_test)]\n",
    "\n",
    "t.append(threshold)\n",
    "a.append(sum(correct)*1.0/len(correct))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|TP  4970 \n",
      "|TN  17314 \n",
      "|FP  0 \n",
      "|FN  3129\n"
     ]
    }
   ],
   "source": [
    "print(\"|TP \",TP,\"\\n|TN \",TN,\"\\n|FP \",FP,\"\\n|FN \",FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BER is  0.19317199654278305\n"
     ]
    }
   ],
   "source": [
    "BER = 1-(0.5*((TP/(TP+FN))+(TN/(TN+FP))))\n",
    "print(\"The BER is \", BER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87687404084523668"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = [ i==j for i,j in zip(test_pred,y_out_test)]\n",
    "sum(correct)*1.0/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.043450835427771395',\n",
       " '0.07367486408976276',\n",
       " '0.07856172352184254',\n",
       " '0.029189645979856627',\n",
       " '0.140048696093102',\n",
       " '0.12566591637800228',\n",
       " 0,\n",
       " '0.06135369737204377',\n",
       " '0.09792402541527445',\n",
       " '0.1789123750220668',\n",
       " '0.4627400919763902',\n",
       " 0,\n",
       " '0.24970466007663183',\n",
       " '0.04499710839762605',\n",
       " '0.36266749342827453',\n",
       " '0.2025148987437202']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling body vectors\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Pickling body vectors\")\n",
    "import pickle\n",
    "with open('LSA_Compare_Features_Test.pkl','wb') as f:\n",
    "    pickle.dump(feature_list,f)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25413"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
